{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cb6c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f075b827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-07 12:51:28--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8001::154, 2606:50c0:8000::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  3.27MB/s    in 0.3s    \n",
      "\n",
      "2023-05-07 12:51:30 (3.27 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a36fb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "87c004c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "c11d625a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "52a10cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "token_list = sorted(list(set(text)))\n",
    "vocab_size = len(token_list)\n",
    "print(len(token_list), token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c065c373",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Every token needs to be encoded into its int value\n",
    "stoi = {ch:i for i, ch in enumerate(textList)}\n",
    "itos = {i:ch for ch, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6f8078cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A given block of tokens needs to encoded into a list of ints\n",
    "\n",
    "def encode(text_block):\n",
    "    encoded_text = []\n",
    "    for ch in text_block:\n",
    "        encoded_text.append(stoi[ch])\n",
    "    return encoded_text\n",
    "\n",
    "def decode(encoded_text):\n",
    "    decoded_text = []\n",
    "    for i in encoded_text:\n",
    "        decoded_text.append(itos[i])\n",
    "    return ''.join(decoded_text)\n",
    "\n",
    "encoded_text = encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "a8acbfb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([892315])"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to split the dataset into train 80%, dev 10%, test sets 10%\n",
    "time_series = block_size = 8\n",
    "\n",
    "xtrain, ytrain = [], []\n",
    "xDev, yDev = [], []\n",
    "xTest, yTest = [], []\n",
    "\n",
    "def get_data_split(split_type):\n",
    "    train_len = int(0.8*len(encoded_text))\n",
    "    val_len = int(0.1*len(encoded_text)) + train_len\n",
    "    \n",
    "    if split_type == \"train\":\n",
    "        x = encoded_text[:train_len]\n",
    "    elif split == \"val\":\n",
    "        x = encoded_text[train_len:val_len]\n",
    "    else:\n",
    "        x = encoded_text[val_len:]\n",
    "        \n",
    "    return torch.tensor(x)\n",
    "\n",
    "train_data = get_data_split(\"train\")\n",
    "val_data = get_data_split(\"val\")\n",
    "test_data = get_data_split(\"test\")\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "cc650ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]),\n",
       " tensor([[50, 39, 52, 58, 43, 56, 52,  6],\n",
       "         [63,  1, 42, 53,  1, 63, 53, 59],\n",
       "         [53, 56,  1, 42, 53,  1, 21,  1],\n",
       "         [ 1, 42, 43, 57, 54, 39, 47, 56]]))"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to get one batch at a time\n",
    "train_batch_size = B = 4\n",
    "val_batch_size = 4\n",
    "\n",
    "def get_batch(split):\n",
    "    if split == \"train\": \n",
    "        batch_size = train_batch_size\n",
    "        data = train_data\n",
    "    elif split == \"val\": \n",
    "        batch_size = val_batch_size\n",
    "        data = val_data\n",
    "    else: \n",
    "        batch_size = test_batch_size\n",
    "        data = test_data\n",
    "#     print(len(data_split))\n",
    "    indexes = torch.randint(len(data)-time_series, (batch_size,))\n",
    "#     print(indexes.shape)\n",
    "    batch_x = torch.stack([data[i: block_size+i] for i in indexes])#.to(torch.float32)\n",
    "    batch_y = torch.stack([data[i+1: block_size+i+1] for i in indexes])#.to(torch.float32)\n",
    "    return batch_x, batch_y\n",
    "\n",
    "\n",
    "x, y = get_batch(\"train\")\n",
    "x.shape, x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "883b8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_size = 16\n",
    "no_blocks = 5\n",
    "no_heads = 4\n",
    "head_size = 16\n",
    "\n",
    "class BigramLanguageModel(torch.nn.Module):\n",
    "    def __init__(self, time_series, channel_size):\n",
    "        super().__init__()\n",
    "        self.token_embed = Linear(vocab_size, channel_size)\n",
    "        self.positional_embed = Linear(vocab_size, channel_size)\n",
    "        self.blocks = torch.nn.Sequential(*[Block(time_series, channel_size, head_size)]*no_blocks)\n",
    "        self.layer_norm = LayerNorm(time_series)\n",
    "        self.linear = Linear(channel_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        x = self.token_embed.W[x] + self.positional_embed.W[x]\n",
    "#         x = self.token_embed(x) + self.positional_embed(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.linear(x)\n",
    "        \n",
    "        if y != None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            y = y.view(B*T)\n",
    "            loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "232699d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5979,  1.3380,  0.7685, -0.7797,  0.0387],\n",
      "        [ 0.0468,  1.7423,  1.3627, -1.4605, -1.2071]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Linear(torch.nn.Module):\n",
    "    def __init__(self, fan_in, fan_out, bias=False):\n",
    "        super().__init__()\n",
    "        self.W = torch.nn.Parameter(torch.randn((fan_in, fan_out)) / (fan_in**0.5))\n",
    "        if bias: self.B = torch.nn.Parameter(torch.randn((fan_out,)))\n",
    "        else: self.B = None\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x @ self.W\n",
    "        if self.B != None: out += self.B\n",
    "            \n",
    "        return out\n",
    "            \n",
    "linear = Linear(3, 5, True)\n",
    "x = torch.randn((2, 3))\n",
    "# print(linear.B, linear.B.shape)\n",
    "print(linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "3dd39427",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 16]), torch.Size([1, 8, 16]))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self, time_series):\n",
    "        super().__init__()\n",
    "        self.gamma = torch.randn((time_series, 1))\n",
    "        self.beta = torch.randn((time_series, 1))\n",
    "        self.epsil = 0.0001\n",
    "        \n",
    "    def forward(self, x): # x -> (B, T, C)\n",
    "        mean = torch.mean(x, dim=2, keepdim=True) # (B, T, 1)\n",
    "        var = torch.var(x, dim=2, keepdim=True)\n",
    "        \n",
    "        out = self.gamma*((x-mean)/(var+self.epsil)**0.5) + self.beta\n",
    "        return out\n",
    "\n",
    "layer = LayerNorm(time_series)\n",
    "x = torch.randn((B, time_series, channel_size))\n",
    "mean = layer(x)\n",
    "mean.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6a5d2a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            Linear(head_size, 4*head_size, bias=True),\n",
    "            Relu(),\n",
    "            Linear(4*head_size, channel_size)\n",
    "#             torch.nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "46a1cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "9d1c579c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, T, C, head_size):\n",
    "        super().__init__()\n",
    "#         self.no_heads = 4\n",
    "        self.heads = torch.nn.ModuleList([Head(T, C, head_size//4) for _ in range(4)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=2) # head(x) -> (B, T, H//4)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3eff4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(torch.nn.Module):\n",
    "    def __init__(self, T, C, head_size):\n",
    "        super().__init__()\n",
    "        self.query = Linear(C, head_size)\n",
    "        self.key = Linear(C, head_size)\n",
    "        self.value = Linear(C, head_size)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(T, T)))\n",
    "        \n",
    "    def forward(self, x): # x -> (B, T, C)\n",
    "        query = self.query(x)\n",
    "        key = self.key(x) \n",
    "        value = self.value(x) # (B, T, H)\n",
    "        \n",
    "        wei = query @ key.transpose(-2, -1) # (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril == 0, -float(\"inf\"))\n",
    "        wei = torch.softmax(wei, dim=2)\n",
    "        \n",
    "        return wei @ value # (B, T, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "524d896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(torch.nn.Module):\n",
    "    def __init__(self, T, C, head_size):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            LayerNorm(T),\n",
    "            MultiHeadAttention(T, C, head_size),\n",
    "            LayerNorm(T),\n",
    "            FeedForward(head_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b8156a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3818,  0.0725, -0.0870, -0.4300,  0.5514, -0.2411],\n",
       "        [ 0.2201,  0.9559, -0.5193, -0.5000, -0.3703,  0.2533],\n",
       "        [ 0.6238,  1.3190,  0.4906, -0.1029, -0.1468,  0.1250],\n",
       "        [ 0.2720,  0.3514, -0.4024, -0.6464, -0.2954,  0.8430]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, C, T, H = 1, 4, 5, 6\n",
    "head = Head(T, C, H)\n",
    "x = torch.randn((B, T, C))\n",
    "head.forward(x)\n",
    "params = head.parameters()\n",
    "next(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a991720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "16891759",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.1009, val loss 5.0929\n",
      "step 100: train loss 4.2075, val loss 4.1723\n",
      "step 200: train loss 3.8840, val loss 3.8977\n",
      "step 300: train loss 3.5858, val loss 3.6317\n",
      "step 400: train loss 3.4831, val loss 3.5293\n",
      "step 500: train loss 3.4288, val loss 3.4714\n",
      "step 600: train loss 3.4067, val loss 3.4557\n",
      "step 700: train loss 3.4110, val loss 3.4149\n",
      "step 800: train loss 3.3788, val loss 3.4067\n",
      "step 900: train loss 3.3742, val loss 3.4147\n",
      "step 1000: train loss 3.3781, val loss 3.4077\n",
      "step 1100: train loss 3.3740, val loss 3.4162\n",
      "step 1200: train loss 3.3666, val loss 3.4391\n",
      "step 1300: train loss 3.3999, val loss 3.3806\n",
      "step 1400: train loss 3.3276, val loss 3.3868\n",
      "step 1500: train loss 3.3720, val loss 3.3986\n",
      "step 1600: train loss 3.3147, val loss 3.3794\n",
      "step 1700: train loss 3.3334, val loss 3.3776\n",
      "step 1800: train loss 3.3210, val loss 3.3693\n",
      "step 1900: train loss 3.3409, val loss 3.4247\n",
      "step 2000: train loss 3.3415, val loss 3.3677\n",
      "step 2100: train loss 3.3133, val loss 3.3752\n",
      "step 2200: train loss 3.3612, val loss 3.4043\n",
      "step 2300: train loss 3.3085, val loss 3.3579\n",
      "step 2400: train loss 3.3582, val loss 3.3778\n",
      "step 2500: train loss 3.3591, val loss 3.3969\n",
      "step 2600: train loss 3.3490, val loss 3.3962\n",
      "step 2700: train loss 3.3399, val loss 3.3630\n",
      "step 2800: train loss 3.2994, val loss 3.4332\n",
      "step 2900: train loss 3.3396, val loss 3.3718\n",
      "step 3000: train loss 3.3299, val loss 3.3758\n",
      "step 3100: train loss 3.3099, val loss 3.3425\n",
      "step 3200: train loss 3.3545, val loss 3.3576\n",
      "step 3300: train loss 3.3228, val loss 3.3666\n",
      "step 3400: train loss 3.3312, val loss 3.3419\n",
      "step 3500: train loss 3.3384, val loss 3.3738\n",
      "step 3600: train loss 3.3143, val loss 3.3734\n",
      "step 3700: train loss 3.3087, val loss 3.3721\n",
      "step 3800: train loss 3.2892, val loss 3.3457\n",
      "step 3900: train loss 3.3278, val loss 3.3178\n",
      "step 4000: train loss 3.2964, val loss 3.3774\n",
      "step 4100: train loss 3.2956, val loss 3.3327\n",
      "step 4200: train loss 3.2981, val loss 3.3305\n",
      "step 4300: train loss 3.3279, val loss 3.3286\n",
      "step 4400: train loss 3.3175, val loss 3.3441\n",
      "step 4500: train loss 3.3150, val loss 3.3626\n",
      "step 4600: train loss 3.3241, val loss 3.3692\n",
      "step 4700: train loss 3.3352, val loss 3.3275\n",
      "step 4800: train loss 3.2982, val loss 3.3209\n",
      "step 4900: train loss 3.3042, val loss 3.3449\n",
      "step 4999: train loss 3.2964, val loss 3.2956\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "#     model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "#     model.train()\n",
    "    return out\n",
    "\n",
    "model = BigramLanguageModel(time_series, channel_size)\n",
    "# # print(next(model.parameters()))\n",
    "# batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "# block_size = time_series = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# eval_iters = 200\n",
    "# n_embd = 64\n",
    "# n_head = 4\n",
    "# n_layer = 4\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "#     every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "# for _ in range(100):\n",
    "#     x, y = get_batch(\"train\")\n",
    "#     loss = model(x, y)\n",
    "#     print(loss)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "617a5d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [*[i for i in range(5)]]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "055affe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 0, 2, 0],\n",
      "        [1, 0, 3, 1, 3],\n",
      "        [1, 1, 1, 0, 3],\n",
      "        [2, 2, 2, 1, 3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2421,  0.0626, -0.9244, -0.5468, -1.2528],\n",
       "         [ 2.2814,  2.0784, -0.8457, -0.8192,  0.2828],\n",
       "         [ 1.4330,  0.0588,  3.0397,  0.0722, -0.4317],\n",
       "         [ 2.2814,  2.0784, -0.8457, -0.8192,  0.2828],\n",
       "         [ 1.4330,  0.0588,  3.0397,  0.0722, -0.4317]],\n",
       "\n",
       "        [[-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [ 1.4330,  0.0588,  3.0397,  0.0722, -0.4317],\n",
       "         [ 0.2421,  0.0626, -0.9244, -0.5468, -1.2528],\n",
       "         [-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [ 0.2421,  0.0626, -0.9244, -0.5468, -1.2528]],\n",
       "\n",
       "        [[-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [ 1.4330,  0.0588,  3.0397,  0.0722, -0.4317],\n",
       "         [ 0.2421,  0.0626, -0.9244, -0.5468, -1.2528]],\n",
       "\n",
       "        [[ 2.2814,  2.0784, -0.8457, -0.8192,  0.2828],\n",
       "         [ 2.2814,  2.0784, -0.8457, -0.8192,  0.2828],\n",
       "         [ 2.2814,  2.0784, -0.8457, -0.8192,  0.2828],\n",
       "         [-1.0457, -1.0525,  0.7554, -1.0383,  1.9414],\n",
       "         [ 0.2421,  0.0626, -0.9244, -0.5468, -1.2528]]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn((4, 5))\n",
    "x = torch.randint(4, (4, 5))\n",
    "print(x)\n",
    "t[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c7898cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 'Disney+ Targeting Geo (country)'),\n",
       "  (1, 'Disney+ Language (Auto-tag)'),\n",
       "  (2, 'Disney+ Brand (Auto-tag)'),\n",
       "  (3, 'Disney+ Title (Auto-tag)'),\n",
       "  (4, 'Disney+ Campaign Objective (Auto-tag)'),\n",
       "  (5, 'Disney+ Content Type (Auto-tag)'),\n",
       "  (6, 'Disney+ Quarter / Timing (Auto-tag)'),\n",
       "  (7, 'Disney+ Targeting Strategy (Auto-tag)'),\n",
       "  (8, 'Disney+ Targeting Type (Auto-tag)'),\n",
       "  (9, 'Disney+ Audience Detail (Auto-tag)'),\n",
       "  (10, 'Disney+ Platform/Vendor Name (Auto-tag)'),\n",
       "  (11, 'Disney+ Placement (Auto-tag)'),\n",
       "  (12, 'Disney+ Device (Auto-tag)'),\n",
       "  (13, 'Disney+ Ad Format (Auto-tag)'),\n",
       "  (14, 'Disney+ Unit Size (Auto-tag)'),\n",
       "  (15, 'Disney+ Channel (Internal)'),\n",
       "  (16, 'Disney+ Creative (Auto-tag)'),\n",
       "  (17, 'Disney+ Detail FreeForm (Auto-tag)'),\n",
       "  (18, 'Disney+ Campaign Owner (Auto-tag)'),\n",
       "  (19, 'Disney+ Product (Auto-tag)'),\n",
       "  (20, 'Disney+ Geo Cluster (Auto-tag)'),\n",
       "  (21, 'Disney+ Placement/Ad ID (Auto-tag)')],\n",
       " 22)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = \"Disney+ Targeting Geo (country)|Disney+ Language (Auto-tag)|Disney+ Brand (Auto-tag)|Disney+ Title (Auto-tag)|Disney+ Campaign Objective (Auto-tag)|Disney+ Content Type (Auto-tag)|Disney+ Quarter / Timing (Auto-tag)|Disney+ Targeting Strategy (Auto-tag)|Disney+ Targeting Type (Auto-tag)|Disney+ Audience Detail (Auto-tag)|Disney+ Platform/Vendor Name (Auto-tag)|Disney+ Placement (Auto-tag)|Disney+ Device (Auto-tag)|Disney+ Ad Format (Auto-tag)|Disney+ Unit Size (Auto-tag)|Disney+ Channel (Internal)|Disney+ Creative (Auto-tag)|Disney+ Detail FreeForm (Auto-tag)|Disney+ Campaign Owner (Auto-tag)|Disney+ Product (Auto-tag)|Disney+ Geo Cluster (Auto-tag)|Disney+ Placement/Ad ID (Auto-tag)\"\n",
    "convList = list(enumerate(conv.split(\"|\")))\n",
    "convList, len(convList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6d63376a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 'KR'),\n",
       "  (1, 'KO'),\n",
       "  (2, 'Multi'),\n",
       "  (3, 'Rotation'),\n",
       "  (4, 'Consid'),\n",
       "  (5, 'Rotation'),\n",
       "  (6, \"23'Q3\"),\n",
       "  (7, 'Prospecting'),\n",
       "  (8, 'Behavior'),\n",
       "  (9, 'Interest'),\n",
       "  (10, 'TikTok'),\n",
       "  (11, 'Feed'),\n",
       "  (12, 'Android'),\n",
       "  (13, 'Multi'),\n",
       "  (14, 'Multi'),\n",
       "  (15, 'Social'),\n",
       "  (16, 'NA'),\n",
       "  (17, 'Android'),\n",
       "  (18, 'DSS'),\n",
       "  (19, 'Disney+'),\n",
       "  (20, 'KR'),\n",
       "  (21, '')],\n",
       " 22)"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"KR|KO|Multi|Rotation|Consid|Rotation|23'Q3|Prospecting|Behavior|Interest|TikTok|Feed|Android|Multi|Multi|Social|NA|Android|DSS|Disney+|KR|\"\n",
    "# name = \"CA|EN|Multi|Rotation|Acq|Commerce|23'Q3|Prospecting|Demo|A18+|FBIG|Feed|CrossDev|Multi|Multi|Social|NA|CommerceCatalog|DSS|Disney+|CA|366389807\"\n",
    "nameList = list(enumerate(name.split(\"|\")))\n",
    "nameList, len(nameList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "72c3d641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Disney+ Targeting Geo (country)           -> KR\n",
      "1: Disney+ Language (Auto-tag)               -> KO\n",
      "2: Disney+ Brand (Auto-tag)                  -> Multi\n",
      "3: Disney+ Title (Auto-tag)                  -> Rotation\n",
      "4: Disney+ Campaign Objective (Auto-tag)     -> Consid\n",
      "5: Disney+ Content Type (Auto-tag)           -> Rotation\n",
      "6: Disney+ Quarter / Timing (Auto-tag)       -> 23'Q3\n",
      "7: Disney+ Targeting Strategy (Auto-tag)     -> Prospecting\n",
      "8: Disney+ Targeting Type (Auto-tag)         -> Behavior\n",
      "9: Disney+ Audience Detail (Auto-tag)        -> Interest\n",
      "10: Disney+ Platform/Vendor Name (Auto-tag)  -> TikTok\n",
      "11: Disney+ Placement (Auto-tag)             -> Feed\n",
      "12: Disney+ Device (Auto-tag)                -> Android\n",
      "13: Disney+ Ad Format (Auto-tag)             -> Multi\n",
      "14: Disney+ Unit Size (Auto-tag)             -> Multi\n",
      "15: Disney+ Channel (Internal)               -> Social\n",
      "16: Disney+ Creative (Auto-tag)              -> NA\n",
      "17: Disney+ Detail FreeForm (Auto-tag)       -> Android\n",
      "18: Disney+ Campaign Owner (Auto-tag)        -> DSS\n",
      "19: Disney+ Product (Auto-tag)               -> Disney+\n",
      "20: Disney+ Geo Cluster (Auto-tag)           -> KR\n",
      "21: Disney+ Placement/Ad ID (Auto-tag)       -> \n"
     ]
    }
   ],
   "source": [
    "for prop, name in zip(convList, nameList):\n",
    "    t= \"\".join([\" \"]*(42-len(prop[1])-len(str(prop[0]))))\n",
    "    print(f\"{prop[0]}: {prop[1]}{t} -> {name[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "9e0ef73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], {})"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "x = dic.get(0, [])\n",
    "x.append(1)\n",
    "x, dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "068b208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [2]]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1]\n",
    "y = [2]\n",
    "x.append(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d4f4c360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Disney+ Detail FreeForm (Auto-tag)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
